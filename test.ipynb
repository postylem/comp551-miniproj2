{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comp551miniproj2 - reddit text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                           comments       subreddits\n",
      "0    0  Honestly, Buffalo is the correct answer. I rem...           hockey\n",
      "1    1  Ah yes way could have been :( remember when he...              nba\n",
      "2    2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...  leagueoflegends\n",
      "3    3  He wouldn't have been a bad signing if we woul...           soccer\n",
      "4    4  Easy. You use the piss and dry technique. Let ...            funny\n",
      "5    5  The joke is on YOU!\\n\\nI've only seen it twice...            funny\n",
      "6    6  His role in MI3 is one of the best villians I'...           movies\n",
      "7    7  Akagi is still Alpha as fuck and Sugawara is s...            anime\n",
      "8    8  I think that they had each other's detonator. ...           movies\n",
      "9    9  Right! He was a disruptor tank! Pull the dps o...        Overwatch\n",
      "10  10  The flying the Eagles to Mordor thing is incre...           movies\n",
      "11  11  \"Oh man I can't wait to vote.\"\\n\\n*opens link*...            anime\n",
      "12  12  omg i was thinking the same.... azumi u the al...            anime\n",
      "13  13  One shot, one kill!\\nWait... that's not the ri...        Overwatch\n",
      "14  14  I'm new to this sub and I was curious. Is the ...            trees\n",
      "15  15  I pay $220/oz in Brooklyn for mid range trees....            trees\n",
      "16  16  I'm glad you're considering a rewatch. This se...            anime\n",
      "17  17  And it's been the same stories all window, sam...           soccer\n",
      "18  18  Not willing to negotiate a contract well after...           soccer\n",
      "19  19  Afraid I'll get addicted and fail school or sm...  GlobalOffensive\n",
      "2968210\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# based on tutorial from https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "df = pd.read_csv('reddit-comment-classification-comp-551/reddit_train.csv')\n",
    "df = df[pd.notnull(df['comments'])]\n",
    "print(df.head(20))\n",
    "print(df['comments'].apply(lambda x: len(x.split(' '))).sum())\n",
    "\n",
    "\n",
    "\n",
    "df.subreddits.value_counts().plot(kind='bar');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are balanced, but the text needs cleaning. Here's some cleaning (we should customize **TODO: we should make something to remove links... that is words starting with `http://` at least, should be ignored**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "ignored_symbols = re.compile('[^0-9a-z #+_]')\n",
    "# nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# def print_plot(index):\n",
    "#     example = df[df.index == index][['comments', 'subreddits']].values[0]\n",
    "#     if len(example) > 0:\n",
    "#         print(example[0])\n",
    "#         print('subreddit:', example[1])\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string (one comment)\n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = delimiters.sub(' ', text) # replace delimiters symbols by space in text\n",
    "    text = ignored_symbols.sub('', text) # delete symbols which are in ignored_symbols from text\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords) # delete stopwords from text\n",
    "    return text\n",
    "    \n",
    "df['comments'] = df['comments'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to lemmatize the corpus.  This might not help in the short term, but will be useful to play with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           comments       subreddits\n",
      "0   0  honest buffalo correct answ rememb peopl somew...           hockey\n",
      "1   1  ah ye way could rememb draft thought gon na gr...              nba\n",
      "2   2  https youtub 6xxbbr8isz0t40m49sif didnt find a...  leagueoflegends\n",
      "3   3  wouldnt bad sign wouldnt paid 18m euro right p...           soccer\n",
      "4   4  easy us piss dry techn let drop let dry rins r...            funny\n",
      "5   5                                  jok you seen twic            funny\n",
      "6   6  rol mi3 on best vil iv seen movy genuin felt l...           movies\n",
      "7   7  akag stil alph fuck sugawar suff definit two f...            anime\n",
      "8   8  think oth deton wouldnt prov jok right blew bo...           movies\n",
      "9   9  right disrupt tank pul dps frey pick get point...        Overwatch\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "def lemmatize_sentence(sen):\n",
    "    \"\"\" lemmatizes every word in space separated sentence sen\"\"\" \n",
    "    token_list = word_tokenize(sen)\n",
    "    lemma_sen = []\n",
    "    for w in token_list:\n",
    "        lemma_sen.append(stemmer.stem(w))\n",
    "    return \" \".join(lemma_sen)\n",
    "\n",
    "df['comments'] = df['comments'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "# print_plot(1234)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could set the train test split here, or we could do some more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array = np.unique(df.subreddits.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get **a list of words in the entire corpus of comments** (that is, `tokens`), and also **a list unique words** (that is `types`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens 1601210\n",
      "number of types 75440\n"
     ]
    }
   ],
   "source": [
    "# import itertools\n",
    "\n",
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words are more common than others.  We might want to do something with this. But for now it's just useful to have the information.  I'll make an uncommon-word list. We can remove them just like we did the stopwords. We'll do this later, with scikitlearn's CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_words = types[type_counts > 20]\n",
    "# len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsize_vocab(text):\n",
    "#     text = ' '.join(word for word in text.split() if word in common_words) # keep only common words\n",
    "#     return text\n",
    "    \n",
    "# df['comments'] = df['comments'].apply(downsize_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is cleand, set the train test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf = TfidfTransformer()\n",
    "#X_tfidf = tfidf.fit_transform(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running sklearn classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "accuracy 0.5337142857142857\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.23      0.30      0.26      1039\n",
      "GlobalOffensive       0.48      0.66      0.56      1028\n",
      "          Music       0.56      0.65      0.61      1011\n",
      "      Overwatch       0.71      0.65      0.68      1085\n",
      "          anime       0.53      0.57      0.55      1067\n",
      "       baseball       0.59      0.59      0.59      1091\n",
      "         canada       0.43      0.49      0.46      1012\n",
      "     conspiracy       0.42      0.41      0.42      1019\n",
      "         europe       0.54      0.50      0.52      1084\n",
      "          funny       0.19      0.28      0.23      1053\n",
      "  gameofthrones       0.74      0.70      0.72      1050\n",
      "         hockey       0.60      0.59      0.59      1013\n",
      "leagueoflegends       0.69      0.62      0.65      1013\n",
      "         movies       0.66      0.56      0.61      1054\n",
      "            nba       0.68      0.61      0.64      1074\n",
      "            nfl       0.69      0.55      0.61      1042\n",
      "         soccer       0.72      0.54      0.62      1125\n",
      "          trees       0.50      0.52      0.51      1072\n",
      "      worldnews       0.42      0.24      0.30      1048\n",
      "            wow       0.65      0.65      0.65      1020\n",
      "\n",
      "       accuracy                           0.53     21000\n",
      "      macro avg       0.55      0.53      0.54     21000\n",
      "   weighted avg       0.55      0.53      0.54     21000\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "runmodel() missing 1 required positional argument: 'modelpipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3038418008ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mparamsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomparison\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mrunmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: runmodel() missing 1 required positional argument: 'modelpipeline'"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bernoulli_nb = Pipeline([\n",
    "                         ('ct_vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', BernoulliNB()),\n",
    "                        ])\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                       alpha=1e-3, random_state=27,\n",
    "                                       max_iter=5, tol=None)),\n",
    "                ])\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(ngram_range=(1,1))),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', KNeighborsClassifier(n_neighbors=200, weights = 'distance')),\n",
    "                ])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()), # works well with more features (all 75440 ...)\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', LogisticRegression(penalty='l2',multi_class='ovr',solver='saga')),\n",
    "                ])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfrst = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(max_features=5000)),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', RandomForestClassifier(n_estimators=10)), # more estimators might be good, but slow\n",
    "                ])\n",
    "\n",
    "# now for comparing and majority voting:\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "logreg = LogisticRegression(penalty='l2',multi_class='ovr',solver='saga')\n",
    "svn = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=27, max_iter=5, tol=None)\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "comparison = Pipeline([\n",
    "    ('ct_vect', CountVectorizer(max_features=60000)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf' , VotingClassifier(estimators=[('logreg', logreg), ('svn', svn), ('bnb', bnb)], voting='hard')),\n",
    "])\n",
    "\n",
    "\n",
    "def paramsearch(modelpipeline):\n",
    "    '''\n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    does gridsearch on the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    parameters = {\n",
    "        #logreg\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [5000,70000],\n",
    "#         'clf__multi_class':['ovr','multinomial'],\n",
    "#         'clf__solver':['sag','saga'],\n",
    "        \n",
    "#       #knn\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [5000],\n",
    "        \n",
    "        #bernoulli_nb\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [10000],\n",
    "#         'clf__alpha': [0.1],\n",
    "        \n",
    "        #sgd\n",
    "#         'ct_vect__ngram_range': [(1,2)],\n",
    "#         'ct_vect__max_features': [5000],\n",
    "#         'clf__alpha': [1e-3, 1e-5],\n",
    "    }\n",
    "    # run gridsearch for parameters with 5-fold cross validation\n",
    "    gridsearch = GridSearchCV(modelpipeline, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "    gridsearch = gridsearch.fit(X_train, y_train)\n",
    "    y_pred = gridsearch.predict(X_test)\n",
    "#     print(gridsearch)\n",
    "    print(gridsearch.best_params_)\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=values_array))\n",
    "\n",
    "def runmodel(modelpipeline):\n",
    "    '''\n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    runs the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    modelpipeline.fit(X_train, y_train)\n",
    "    y_pred = modelpipeline.predict(X_test)\n",
    "    print(modelpipeline)\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred,target_names=values_array))\n",
    "\n",
    "paramsearch(comparison)\n",
    "\n",
    "runmodel(logreg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_naive_bayes(observations, y, num_features,smoothing):\n",
    "\n",
    "    #Initialize marginal probability for each class\n",
    "    count_class = np.array(20*[[0]])\n",
    "    marg_prob = np.array(20*[[1]]) #Laplace smoothing, starting counts with 1\n",
    "\n",
    "    #Initialize matrix of probabilities of observed features given k\n",
    "    cond_prob_matrix = np.ones((20,num_features)) * smoothing\n",
    "\n",
    "    \n",
    "    #compute marginal probability of each class\n",
    "    total_comments = y.shape[0]\n",
    "    for j in range(total_comments):\n",
    "        count_class[y[j]] += 1\n",
    "    \n",
    "    #Marginal probability for each class\n",
    "    marg_prob = np.true_divide(count_class, total_comments)\n",
    "\n",
    "    \n",
    "    observ = observations.nonzero()\n",
    "    for i in range(observations.shape[0]):\n",
    "        feature_no = observ[1][i]\n",
    "        comment_no = observ[0][i]\n",
    "       \n",
    "        comment_class = y[comment_no]\n",
    "        cond_prob_matrix[comment_class][feature_no] += 1\n",
    "\n",
    "    #divide each row of cond_prob_matrix by the count of comments per class\n",
    "    for i in range(20):\n",
    "        cond_prob_matrix[i] = np.true_divide(cond_prob_matrix[i], count_class[i])\n",
    "\n",
    "\n",
    "    cond_prob_matrix = cond_prob_matrix.transpose()\n",
    "    marg_prob = np.log(marg_prob)\n",
    "\n",
    "    return marg_prob, cond_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "        \"anime\": 1,\n",
    "        \"AskReddit\": 2,\n",
    "        \"baseball\": 3,\n",
    "        \"canada\": 4, \n",
    "        \"conspiracy\": 5, \n",
    "        \"europe\": 6, \n",
    "        \"funny\": 7, \n",
    "        \"gameofthrones\": 8, \n",
    "        \"GlobalOffensive\": 9,\n",
    "        \"hockey\" :10, \n",
    "        \"leagueoflegends\": 11, \n",
    "        \"movies\": 12, \n",
    "        \"Music\": 13, \n",
    "        \"nba\":14, \n",
    "        \"nfl\":15, \n",
    "        \"Overwatch\":16, \n",
    "        \"soccer\":17, \n",
    "        \"trees\":18, \n",
    "        \"worldnews\":19, \n",
    "        \"wow\":0\n",
    "    }\n",
    "\n",
    "y_traindf = pd.DataFrame(y_train)\n",
    "y_traindf['subreddits']= y_traindf['subreddits'].map(classes)\n",
    "y_train_array = np.array(y_traindf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1000)\n",
    "X_train_tf = cv.fit_transform(X_train)\n",
    "X_test_tf = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.23935413360595703 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# from naive_bayes import fit_naive_bayes\n",
    "prior, conditional = fit_naive_bayes(X_train_tf, y_train_array, X_train_tf.shape[1],0.1)\n",
    "\n",
    "print(\"Took %s seconds.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = X_test.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def predict_naive_bayes(id_list, observations, marg_prob, cond_prob_matrix):\n",
    "\n",
    "    #log of inverse conditional probability matrix\n",
    "    inv_cond_prob_matrix = np.ones((cond_prob_matrix.shape[0], cond_prob_matrix.shape[1]))\n",
    "    inv_cond_prob_matrix = inv_cond_prob_matrix - cond_prob_matrix\n",
    "    inv_cond_prob_matrix = sparse.csr_matrix(np.log(inv_cond_prob_matrix))\n",
    "\n",
    "    #log of conditional probability matrix\n",
    "    cond_prob_matrix = sparse.csr_matrix(np.log(cond_prob_matrix))\n",
    "    \n",
    "    # 0s become 1s, 1s become 0s\n",
    "    sparse_ones = sparse.csr_matrix(np.ones((observations.shape[0], observations.shape[1])))\n",
    "    complement_obs = sparse_ones - observations\n",
    "\n",
    "    prob_per_class = np.dot(observations,cond_prob_matrix) + np.dot(complement_obs,inv_cond_prob_matrix)\n",
    "\n",
    "    y = []\n",
    "    for i in range(observations.shape[0]):\n",
    "        prob_per_class[i] += marg_prob.transpose()\n",
    "        y.append(np.argmax(prob_per_class[i]))\n",
    "\n",
    "    id_list = np.array(id_list).transpose()\n",
    "\n",
    "    matrix = np.stack((id_list, y)).transpose()\n",
    "    df_pred = pd.DataFrame(matrix)\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_naive_bayes(ID_list, X_test_tf, prior, conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16099</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35596</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62735</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>67323</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20995</td>\n",
       "      <td>23873</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20996</td>\n",
       "      <td>15156</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20997</td>\n",
       "      <td>1645</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20998</td>\n",
       "      <td>4919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20999</td>\n",
       "      <td>50805</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1\n",
       "0      26505   2\n",
       "1      16099  19\n",
       "2      35596  19\n",
       "3      62735   8\n",
       "4      67323   6\n",
       "...      ...  ..\n",
       "20995  23873   9\n",
       "20996  15156  18\n",
       "20997   1645  15\n",
       "20998   4919   4\n",
       "20999  50805   4\n",
       "\n",
       "[21000 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testdf = pd.DataFrame(y_test)\n",
    "y_testdf['subreddits']= y_testdf['subreddits'].map(classes)\n",
    "y_test_array = np.array(y_testdf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1        19\n",
       "2        19\n",
       "3         8\n",
       "4         6\n",
       "         ..\n",
       "20995     9\n",
       "20996    18\n",
       "20997    15\n",
       "20998     4\n",
       "20999     4\n",
       "Name: 1, Length: 21000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df_pred, df_true_y):\n",
    "\n",
    "    pred = np.array(df_pred[1])\n",
    "    true_y = np.array(df_true_y['subreddits'])\n",
    "\n",
    "    count = 0\n",
    "    total = len(true_y)\n",
    "    for i in range(total):\n",
    "        if pred[i] == true_y[i]:\n",
    "            count +=1\n",
    "            \n",
    "    return float(count)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3038095238095238"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions, y_testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
