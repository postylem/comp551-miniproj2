{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comp551miniproj2 - reddit text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           comments       subreddits\n",
      "0   0  Honestly, Buffalo is the correct answer. I rem...           hockey\n",
      "1   1  Ah yes way could have been :( remember when he...              nba\n",
      "2   2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...  leagueoflegends\n",
      "3   3  He wouldn't have been a bad signing if we woul...           soccer\n",
      "4   4  Easy. You use the piss and dry technique. Let ...            funny\n",
      "5   5  The joke is on YOU!\\n\\nI've only seen it twice...            funny\n",
      "6   6  His role in MI3 is one of the best villians I'...           movies\n",
      "7   7  Akagi is still Alpha as fuck and Sugawara is s...            anime\n",
      "8   8  I think that they had each other's detonator. ...           movies\n",
      "9   9  Right! He was a disruptor tank! Pull the dps o...        Overwatch\n",
      "2968210\n",
      "   id                                           comments\n",
      "0   0  Trout and Bryant have both led the league in s...\n",
      "1   1  &gt; Just like Estonians have good reasons to ...\n",
      "2   2  Will Sol_Primeval sotp being oblivious?\\n\\nfin...\n",
      "3   3  Moving Ostwald borders back to the pre 1967 bo...\n",
      "4   4         You have to take it out of the bag, Morty!\n",
      "5   5  Don't forget the obnoxious \"*memes*\" in every ...\n",
      "6   6  I say encourage local team support. Half the f...\n",
      "7   7  Favorite type of pasta? (not dish, pasta shape...\n",
      "8   8  Spinal meningitis- Ween.\\n\\nOn mobile, so no l...\n",
      "9   9  So what about Scandinavians, Caucasians, Asian...\n",
      "1257851\n"
     ]
    }
   ],
   "source": [
    "# some of the following based on tutorial from https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "df = pd.read_csv('reddit-comment-classification-comp-551/reddit_train.csv')\n",
    "df = df[pd.notnull(df['comments'])]\n",
    "print(df.head(10))\n",
    "print(df['comments'].apply(lambda x: len(x.split(' '))).sum())\n",
    "\n",
    "X_kaggle = pd.read_csv('reddit-comment-classification-comp-551/reddit_test.csv')\n",
    "X_kaggle = X_kaggle[pd.notnull(X_kaggle['comments'])]\n",
    "print(X_kaggle.head(10))\n",
    "print(X_kaggle['comments'].apply(lambda x: len(x.split(' '))).sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are balanced, but the text needs cleaning. Here's some cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "delimiters = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "ignored_symbols = re.compile('[^0-9a-z #+_]')\n",
    "# nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string (one comment)\n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "#     text = BeautifulSoup(text, \"lxml\").text # HTML decoding # our pipeline does slightly better without this.\n",
    "    text = text.lower() # lowercase text\n",
    "    text = delimiters.sub(' ', text) # replace delimiters symbols by space in text\n",
    "    text = ignored_symbols.sub('', text) # delete symbols which are in ignored_symbols from text\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords) # delete stopwords from text\n",
    "    return text\n",
    "    \n",
    "df['comments'] = df['comments'].apply(clean_text)\n",
    "\n",
    "#COMPETITION SET\n",
    "X_kaggle['comments'] = X_kaggle['comments'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to lemmatize the corpus.  This might not help in the short term, but will be useful to play with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           comments       subreddits\n",
      "0   0  honestli buffalo correct answer rememb peopl s...           hockey\n",
      "1   1  ah ye way could rememb draft thought gon na gr...              nba\n",
      "2   2  http youtub 6xxbbr8isz0t40m49sif didnt find al...  leagueoflegends\n",
      "3   3  wouldnt bad sign wouldnt paid 18m euro right p...           soccer\n",
      "4   4  easi use piss dri techniqu let drop let dri ri...            funny\n",
      "5   5                              joke youiv seen twice            funny\n",
      "6   6  role mi3 one best villian ive seen movi genuin...           movies\n",
      "7   7  akagi still alpha fuck sugawara suffer definit...            anime\n",
      "8   8  think other deton wouldnt proven joker right b...           movies\n",
      "9   9  right disruptor tank pull dp frey pick get poi...        Overwatch\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer\n",
    "#stemmer = LancasterStemmer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_sentence(sen):\n",
    "    \"\"\" stems every word in space separated sentence sen \"\"\" \n",
    "    token_list = word_tokenize(sen)\n",
    "    stem_sen = []\n",
    "    for w in token_list:\n",
    "        stem_sen.append(stemmer.stem(w))\n",
    "    return \" \".join(stem_sen)\n",
    "\n",
    "# Download wordnet (could take a little while!), to do lemmatization\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem import WordNetLemmatizer \n",
    "# lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "# def lemm_sentence(sen):\n",
    "#     \"\"\" lemmatizes every word in space separated sentence sen \"\"\" \n",
    "#     token_list = word_tokenize(sen)\n",
    "#     lemma_sen = []\n",
    "#     for w in token_list:\n",
    "#         lemma_sen.append(lemmatizer.lemmatize(w))\n",
    "#     return \" \".join(lemma_sen)\n",
    "\n",
    "\n",
    "# choose lemm_sentence)() for lemmatization, or stem_sentence() for stemming.\n",
    "df['comments'] = df['comments'].apply(lambda x: stem_sentence(x))\n",
    "\n",
    "# print_plot(1234)\n",
    "print(df.head(10))\n",
    "\n",
    "#COMPETITION SET\n",
    "# choose lemm_sentence)() for lemmatization, or stem_sentence() for stemming.\n",
    "X_kaggle['comments'] = X_kaggle['comments'].apply(lambda x: stem_sentence(x))\n",
    "X_kaggle = pd.Series(X_kaggle['comments'], index=X_kaggle.index)\n",
    "# print_plot(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could set the train test split here, but we could also do some more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array = np.unique(df.subreddits.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get **a list of words in the entire corpus of comments** (that is, `tokens`), and also **a list unique words** (that is `types`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words are more common than others.  We might want to do something with this. But for now it's just useful to have the information.  I'll make an uncommon-word list. We can remove them just like we did the stopwords. *We'll do this later, with scikitlearn's CountVectorizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_words = types[type_counts > 20]\n",
    "# len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsize_vocab(text):\n",
    "#     text = ' '.join(word for word in text.split() if word in common_words) # keep only common words\n",
    "#     return text\n",
    "    \n",
    "# df['comments'] = df['comments'].apply(downsize_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is cleand, set the train test split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf = TfidfTransformer()\n",
    "#X_tfidf = tfidf.fit_transform(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running sklearn classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "0.5563063225039012\n",
      "accuracy 0.575047619047619\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.22      0.31      0.26      1003\n",
      "GlobalOffensive       0.65      0.70      0.68      1030\n",
      "          Music       0.60      0.70      0.64      1050\n",
      "      Overwatch       0.63      0.70      0.66      1049\n",
      "          anime       0.62      0.64      0.63      1056\n",
      "       baseball       0.68      0.62      0.65      1060\n",
      "         canada       0.42      0.52      0.47      1030\n",
      "     conspiracy       0.41      0.47      0.44      1047\n",
      "         europe       0.51      0.55      0.53      1039\n",
      "          funny       0.27      0.18      0.21      1084\n",
      "  gameofthrones       0.78      0.74      0.76      1083\n",
      "         hockey       0.71      0.61      0.66      1059\n",
      "leagueoflegends       0.74      0.63      0.68      1043\n",
      "         movies       0.60      0.60      0.60      1051\n",
      "            nba       0.69      0.66      0.67      1025\n",
      "            nfl       0.71      0.63      0.67      1055\n",
      "         soccer       0.74      0.62      0.67      1053\n",
      "          trees       0.56      0.58      0.57      1074\n",
      "      worldnews       0.36      0.30      0.33      1046\n",
      "            wow       0.74      0.73      0.73      1063\n",
      "\n",
      "       accuracy                           0.58     21000\n",
      "      macro avg       0.58      0.57      0.58     21000\n",
      "   weighted avg       0.58      0.58      0.58     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bernoulli_nb = Pipeline([\n",
    "                         ('ct_vect', CountVectorizer(binary=True)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', BernoulliNB(alpha=0.1)),\n",
    "                        ])\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomial_nb = Pipeline([\n",
    "                         ('ct_vect', CountVectorizer(binary=False)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', MultinomialNB(alpha=0.1)),\n",
    "                        ])\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "complement_nb = Pipeline([\n",
    "                         ('ct_vect', CountVectorizer(binary=False)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', ComplementNB(alpha=1)),\n",
    "                        ])\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', SGDClassifier(loss='modified_huber', penalty='l2',\n",
    "                                       alpha=1e-4, random_state=27,\n",
    "                                       max_iter=5, tol=None)),\n",
    "                ])\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(ngram_range=(1,1))),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', KNeighborsClassifier(n_neighbors=300, weights = 'distance')),\n",
    "                ])\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()), # works well with more features (all 75440 ...)\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', LogisticRegression(penalty='l2',multi_class='ovr',solver='saga')),\n",
    "                ])\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randfrst = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(max_features=5000)),\n",
    "                 ('feature_selection', SelectFromModel(LinearSVC(C=0.1, penalty=\"l1\", dual=False))), # optional\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', RandomForestClassifier(n_estimators=10)), # more estimators might be good, but slow\n",
    "                ])\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer(max_features=5000)),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MLPClassifier(alpha=1, max_iter=100)),\n",
    "                ])\n",
    "\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "passaggr = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', PassiveAggressiveClassifier(fit_intercept=True,C=0.1)),\n",
    "                ])\n",
    "\n",
    "# now for comparing and majority voting:\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = LogisticRegression(penalty='l2',multi_class='ovr',solver='saga')\n",
    "clf2 = MultinomialNB(alpha=0.1)\n",
    "clf3 = ComplementNB(alpha=1)\n",
    "clf4 = PassiveAggressiveClassifier(fit_intercept=True,C=0.1) # won't work with voting='soft'\n",
    "clf5 = SGDClassifier(loss='modified_huber', penalty='l2',alpha=1e-4, random_state=27, max_iter=5, tol=None)\n",
    "clf6 = KNeighborsClassifier(n_neighbors=300, weights = 'distance')\n",
    "\n",
    "voting_clf = Pipeline([\n",
    "    ('ct_vect', CountVectorizer(binary=False,ngram_range=(1,1))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf' , VotingClassifier(estimators=\n",
    "                              [('logreg', clf1), ('mnb', clf2), ('cnb', clf3)],\n",
    "                              voting='hard',n_jobs=-1))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "parameters = {\n",
    "        #passagr\n",
    "#         'clf__C':[0.5,0.1,0.01]\n",
    "        #voting\n",
    "#         'clf__voting':['hard','soft'],\n",
    "#         'clf__estimators':[\n",
    "#             [('logreg', clf1), ('mnb', clf2), ('cnb', clf3)],\n",
    "#             [('logreg', clf1), ('mnb', clf2), ('cnb', clf3),('sgd', clf5)],\n",
    "#             [('logreg', clf1), ('mnb', clf2), ('cnb', clf3),('sgd', clf5)],\n",
    "#         ]\n",
    "        #logreg\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [1000,5000,74000],\n",
    "#         'clf__multi_class':['ovr','multinomial'],\n",
    "#         'clf__solver':['sag','saga'],\n",
    "        \n",
    "#       #knn\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [5000,74000],\n",
    "#         'clf__n_neighbors':[3,30],\n",
    "        \n",
    "        #bernoulli_nb\n",
    "#         'ct_vect__ngram_range': [(1,1)],\n",
    "#         'ct_vect__max_features': [10000],\n",
    "#         'clf__alpha': [1,1e-2,1e-3],\n",
    "        \n",
    "        #sgd\n",
    "#         'ct_vect__ngram_range': [(1,1),(1,2)],\n",
    "#         'ct_vect__max_features': [5000],\n",
    "#         'clf__alpha': [1e-3, 1e-5],\n",
    "#         'clf__loss': ['modified_huber', 'hinge'],\n",
    "    }\n",
    "\n",
    "def paramsearch(modelpipeline,parameters):\n",
    "    '''\n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    does gridsearch on the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # run gridsearch for parameters with 3-fold cross validation\n",
    "    gridsearch = GridSearchCV(modelpipeline, parameters, cv=3, iid=False, n_jobs=-1)\n",
    "    gridsearch = gridsearch.fit(X_train, y_train)\n",
    "    y_pred = gridsearch.predict(X_test)\n",
    "    print(gridsearch.best_params_)\n",
    "    print(gridsearch.best_score_)\n",
    "    print('accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=values_array))\n",
    "\n",
    "    return gridsearch\n",
    "\n",
    "def runmodel(modelpipeline):\n",
    "    '''\n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    runs the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    modelpipeline.fit(X_train, y_train)\n",
    "    y_pred = modelpipeline.predict(X_test)\n",
    "    # print(modelpipeline)\n",
    "    print('accuracy %.3f' % accuracy_score(y_test, y_pred))\n",
    "    # print(classification_report(y_test, y_pred,target_names=values_array))\n",
    "\n",
    "    \n",
    "    \n",
    "gridsearch = paramsearch(voting_clf,parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.566\n",
      "took 1.958 seconds for ComplementNB(alpha=1, class_prior=None, fit_prior=True, norm=False)\n",
      "accuracy 0.558\n",
      "took 1.921 seconds for MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
      "accuracy 0.552\n",
      "took 9.028 seconds for SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
      "              max_iter=5, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=27, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "accuracy 0.539\n",
      "took 5.798 seconds for PassiveAggressiveClassifier(C=0.1, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "accuracy 0.517\n",
      "took 1.933 seconds for BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "accuracy 0.540\n",
      "took 12.826 seconds for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "accuracy 0.483\n",
      "took 32.978 seconds for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=300, p=2,\n",
      "                     weights='distance')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "models = [\n",
    "          complement_nb,\n",
    "          multinomial_nb,\n",
    "          sgd,\n",
    "          passaggr,\n",
    "          bernoulli_nb,\n",
    "          logreg,\n",
    "          knn\n",
    "          # randfrst, #only gets 37\n",
    "          ]\n",
    "\n",
    "for model in models:\n",
    "    start_time = time.time()\n",
    "    runmodel(model)\n",
    "    print(\"took %.3f seconds for %s\" % ((time.time() - start_time), model['clf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# adaboost = Pipeline([\n",
    "#                  ('ct_vect', CountVectorizer()),\n",
    "#                  ('tfidf', TfidfTransformer()),\n",
    "#                  ('clf', AdaBoostClassifier(\n",
    "#                     ComplementNB(alpha=1),\n",
    "#                     n_estimators=200,\n",
    "#                     learning_rate=1))\n",
    "#                 ]) ## currently getting accuracy 0.44776\n",
    "\n",
    "# adaparameters = {\n",
    "# #         'ct_vect__ngram_range': [(1,1),(1,2)],\n",
    "# #         'ct_vect__max_features': [5000,7000],\n",
    "# #         'clf__base_estimator__alpha': [1, 0.1, 1e-3],\n",
    "# #         'clf__learning_rate': [0.001,0.1,1],\n",
    "#     }\n",
    "# adagrid = paramsearch(adaboost,adaparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>anime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29995</td>\n",
       "      <td>29995</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29996</td>\n",
       "      <td>29996</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29997</td>\n",
       "      <td>29997</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29998</td>\n",
       "      <td>29998</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29999</td>\n",
       "      <td>29999</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id         Category\n",
       "0          0         baseball\n",
       "1          1           europe\n",
       "2          2            anime\n",
       "3          3        worldnews\n",
       "4          4            trees\n",
       "...      ...              ...\n",
       "29995  29995           movies\n",
       "29996  29996        AskReddit\n",
       "29997  29997  GlobalOffensive\n",
       "29998  29998    gameofthrones\n",
       "29999  29999              wow\n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAKE PREDICTIONS FOR THE HELDOUT COMPETITION SET\n",
    "y_kaggle = gridsearch.predict(X_kaggle)\n",
    "y_kaggle = pd.Series(y_kaggle, index=X_kaggle.index)\n",
    "y_kaggle = pd.DataFrame(y_kaggle)\n",
    "y_kaggle['Id_'] = y_kaggle.index\n",
    "y_kaggle.insert(loc = 0, column = \"Id\", value = y_kaggle['Id_'])\n",
    "y_kaggle = y_kaggle.drop(columns=['Id_'])\n",
    "y_kaggle = y_kaggle.rename(columns={0: \"Category\"})\n",
    "y_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kaggle.to_csv(\"predictions5750.csv\", index=False, sep = ',') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_naive_bayes(observations, y, num_features,smoothing):\n",
    "\n",
    "    #Initialize marginal probability for each class\n",
    "    count_class = np.array(20*[[0]])\n",
    "    marg_prob = np.array(20*[[1]]) #Laplace smoothing, starting counts with 1\n",
    "\n",
    "    #Initialize matrix of probabilities of observed features given k\n",
    "    cond_prob_matrix = np.ones((20,num_features)) * smoothing\n",
    "\n",
    "    \n",
    "    #compute marginal probability of each class\n",
    "    total_comments = y.shape[0]\n",
    "    for j in range(total_comments):\n",
    "        count_class[y[j]] += 1\n",
    "    \n",
    "    #Marginal probability for each class\n",
    "    marg_prob = np.true_divide(count_class, total_comments)\n",
    "\n",
    "    \n",
    "    observ = observations.nonzero()\n",
    "    for i in range(observations.shape[0]):\n",
    "        feature_no = observ[1][i]\n",
    "        comment_no = observ[0][i]\n",
    "       \n",
    "        comment_class = y[comment_no]\n",
    "        cond_prob_matrix[comment_class][feature_no] += 1\n",
    "\n",
    "    #divide each row of cond_prob_matrix by the count of comments per class\n",
    "    for i in range(20):\n",
    "        cond_prob_matrix[i] = np.true_divide(cond_prob_matrix[i], count_class[i])\n",
    "\n",
    "\n",
    "    cond_prob_matrix = cond_prob_matrix.transpose()\n",
    "    marg_prob = np.log(marg_prob)\n",
    "\n",
    "    return marg_prob, cond_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "        \"anime\": 1,\n",
    "        \"AskReddit\": 2,\n",
    "        \"baseball\": 3,\n",
    "        \"canada\": 4, \n",
    "        \"conspiracy\": 5, \n",
    "        \"europe\": 6, \n",
    "        \"funny\": 7, \n",
    "        \"gameofthrones\": 8, \n",
    "        \"GlobalOffensive\": 9,\n",
    "        \"hockey\" :10, \n",
    "        \"leagueoflegends\": 11, \n",
    "        \"movies\": 12, \n",
    "        \"Music\": 13, \n",
    "        \"nba\":14, \n",
    "        \"nfl\":15, \n",
    "        \"Overwatch\":16, \n",
    "        \"soccer\":17, \n",
    "        \"trees\":18, \n",
    "        \"worldnews\":19, \n",
    "        \"wow\":0\n",
    "    }\n",
    "\n",
    "y_traindf = pd.DataFrame(y_train)\n",
    "y_traindf['subreddits']= y_traindf['subreddits'].map(classes)\n",
    "y_train_array = np.array(y_traindf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=7000,binary=True)\n",
    "X_train_tf = cv.fit_transform(X_train)\n",
    "X_test_tf = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.2172222137451172 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# from naive_bayes import fit_naive_bayes\n",
    "prior, conditional = fit_naive_bayes(X_train_tf, y_train_array, X_train_tf.shape[1],0.1)\n",
    "\n",
    "print(\"Took %s seconds.\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = X_test.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def predict_naive_bayes(id_list, observations, marg_prob, cond_prob_matrix):\n",
    "\n",
    "    #log of inverse conditional probability matrix\n",
    "    inv_cond_prob_matrix = np.ones((cond_prob_matrix.shape[0], cond_prob_matrix.shape[1]))\n",
    "    inv_cond_prob_matrix = inv_cond_prob_matrix - cond_prob_matrix\n",
    "    inv_cond_prob_matrix = sparse.csr_matrix(np.log(inv_cond_prob_matrix))\n",
    "\n",
    "    #log of conditional probability matrix\n",
    "    cond_prob_matrix = sparse.csr_matrix(np.log(cond_prob_matrix))\n",
    "    \n",
    "    # 0s become 1s, 1s become 0s\n",
    "    sparse_ones = sparse.csr_matrix(np.ones((observations.shape[0], observations.shape[1])))\n",
    "    complement_obs = sparse_ones - observations\n",
    "\n",
    "    prob_per_class = np.dot(observations,cond_prob_matrix) + np.dot(complement_obs,inv_cond_prob_matrix)\n",
    "\n",
    "    y = []\n",
    "    for i in range(observations.shape[0]):\n",
    "        prob_per_class[i] += marg_prob.transpose()\n",
    "        y.append(np.argmax(prob_per_class[i]))\n",
    "\n",
    "    id_list = np.array(id_list).transpose()\n",
    "\n",
    "    matrix = np.stack((id_list, y)).transpose()\n",
    "    df_pred = pd.DataFrame(matrix)\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_naive_bayes(ID_list, X_test_tf, prior, conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16099</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35596</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62735</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>67323</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20995</td>\n",
       "      <td>23873</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20996</td>\n",
       "      <td>15156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20997</td>\n",
       "      <td>1645</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20998</td>\n",
       "      <td>4919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20999</td>\n",
       "      <td>50805</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1\n",
       "0      26505   2\n",
       "1      16099  19\n",
       "2      35596   2\n",
       "3      62735   8\n",
       "4      67323   6\n",
       "...      ...  ..\n",
       "20995  23873   9\n",
       "20996  15156   2\n",
       "20997   1645  15\n",
       "20998   4919   4\n",
       "20999  50805  15\n",
       "\n",
       "[21000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testdf = pd.DataFrame(y_test)\n",
    "y_testdf['subreddits']= y_testdf['subreddits'].map(classes)\n",
    "y_test_array = np.array(y_testdf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1        19\n",
       "2         2\n",
       "3         8\n",
       "4         6\n",
       "         ..\n",
       "20995     9\n",
       "20996     2\n",
       "20997    15\n",
       "20998     4\n",
       "20999    15\n",
       "Name: 1, Length: 21000, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df_pred, df_true_y):\n",
    "\n",
    "    pred = np.array(df_pred[1])\n",
    "    true_y = np.array(df_true_y['subreddits'])\n",
    "\n",
    "    count = 0\n",
    "    total = len(true_y)\n",
    "    for i in range(total):\n",
    "        if pred[i] == true_y[i]:\n",
    "            count +=1\n",
    "            \n",
    "    return float(count)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3078571428571429\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.44      0.48      0.46      1020\n",
      "GlobalOffensive       0.30      0.43      0.36      1067\n",
      "          Music       0.13      0.14      0.13      1039\n",
      "      Overwatch       0.48      0.16      0.25      1091\n",
      "          anime       0.16      0.54      0.24      1012\n",
      "       baseball       0.22      0.24      0.23      1019\n",
      "         canada       0.29      0.30      0.29      1084\n",
      "     conspiracy       0.18      0.05      0.08      1053\n",
      "         europe       0.45      0.55      0.50      1050\n",
      "          funny       0.38      0.33      0.35      1028\n",
      "  gameofthrones       0.37      0.27      0.31      1013\n",
      "         hockey       0.37      0.32      0.34      1013\n",
      "leagueoflegends       0.31      0.26      0.28      1054\n",
      "         movies       0.32      0.52      0.40      1011\n",
      "            nba       0.49      0.25      0.33      1074\n",
      "            nfl       0.47      0.19      0.28      1042\n",
      "         soccer       0.44      0.44      0.44      1085\n",
      "          trees       0.44      0.25      0.31      1125\n",
      "      worldnews       0.34      0.30      0.32      1072\n",
      "            wow       0.18      0.16      0.17      1048\n",
      "\n",
      "       accuracy                           0.31     21000\n",
      "      macro avg       0.34      0.31      0.30     21000\n",
      "   weighted avg       0.34      0.31      0.30     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predictions, y_testdf))\n",
    "print(classification_report(y_testdf['subreddits'], predictions[1],target_names=values_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another implementation of Bernoulli, thos one from an online tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnotherBernoulliNB(object):\n",
    "    ''' based on https://kenzotakahashi.github.io/naive-bayes-from-scratch-in-python.html '''\n",
    "    def __init__(self, alpha = 1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        count_sample = X.shape[0]\n",
    "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "        self.class_log_prior_ = [np.log(len(i) / count_sample) for i in separated]\n",
    "        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n",
    "        smoothing = 2 * self.alpha\n",
    "        n_doc = np.array([len(i) + smoothing for i in separated])\n",
    "        self.feature_prob_ = count / n_doc[np.newaxis].T\n",
    "        return self\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        return [(np.log(self.feature_prob_) * x + \\\n",
    "                 np.log(1 - self.feature_prob_) * np.abs(x - 1)\n",
    "                ).sum(axis=1) + self.class_log_prior_ for x in X]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=0.1)\n",
    "nb.fit(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpredictions = nb.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26505</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16099</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35596</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62735</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67323</td>\n",
       "      <td>baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23873</td>\n",
       "      <td>GlobalOffensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15156</td>\n",
       "      <td>funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1645</td>\n",
       "      <td>soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4919</td>\n",
       "      <td>trees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50805</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subreddits\n",
       "26505            funny\n",
       "16099        AskReddit\n",
       "35596        AskReddit\n",
       "62735    gameofthrones\n",
       "67323         baseball\n",
       "...                ...\n",
       "23873  GlobalOffensive\n",
       "15156            funny\n",
       "1645            soccer\n",
       "4919             trees\n",
       "50805              nfl\n",
       "\n",
       "[21000 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(y_test)\n",
    "prediction_df['subreddits'] = pd.DataFrame(newpredictions)[0].values\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4810952380952381\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.44      0.48      0.46      1020\n",
      "GlobalOffensive       0.30      0.43      0.36      1067\n",
      "          Music       0.13      0.14      0.13      1039\n",
      "      Overwatch       0.48      0.16      0.25      1091\n",
      "          anime       0.16      0.54      0.24      1012\n",
      "       baseball       0.22      0.24      0.23      1019\n",
      "         canada       0.29      0.30      0.29      1084\n",
      "     conspiracy       0.18      0.05      0.08      1053\n",
      "         europe       0.45      0.55      0.50      1050\n",
      "          funny       0.38      0.33      0.35      1028\n",
      "  gameofthrones       0.37      0.27      0.31      1013\n",
      "         hockey       0.37      0.32      0.34      1013\n",
      "leagueoflegends       0.31      0.26      0.28      1054\n",
      "         movies       0.32      0.52      0.40      1011\n",
      "            nba       0.49      0.25      0.33      1074\n",
      "            nfl       0.47      0.19      0.28      1042\n",
      "         soccer       0.44      0.44      0.44      1085\n",
      "          trees       0.44      0.25      0.31      1125\n",
      "      worldnews       0.34      0.30      0.32      1072\n",
      "            wow       0.18      0.16      0.17      1048\n",
      "\n",
      "       accuracy                           0.31     21000\n",
      "      macro avg       0.34      0.31      0.30     21000\n",
      "   weighted avg       0.34      0.31      0.30     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_test, prediction_df))\n",
    "print(classification_report(y_testdf['subreddits'], predictions[1],target_names=values_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
