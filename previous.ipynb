{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                           comments       subreddits\n",
      "0    0  Honestly, Buffalo is the correct answer. I rem...           hockey\n",
      "1    1  Ah yes way could have been :( remember when he...              nba\n",
      "2    2  https://youtu.be/6xxbBR8iSZ0?t=40m49s\\n\\nIf yo...  leagueoflegends\n",
      "3    3  He wouldn't have been a bad signing if we woul...           soccer\n",
      "4    4  Easy. You use the piss and dry technique. Let ...            funny\n",
      "5    5  The joke is on YOU!\\n\\nI've only seen it twice...            funny\n",
      "6    6  His role in MI3 is one of the best villians I'...           movies\n",
      "7    7  Akagi is still Alpha as fuck and Sugawara is s...            anime\n",
      "8    8  I think that they had each other's detonator. ...           movies\n",
      "9    9  Right! He was a disruptor tank! Pull the dps o...        Overwatch\n",
      "10  10  The flying the Eagles to Mordor thing is incre...           movies\n",
      "11  11  \"Oh man I can't wait to vote.\"\\n\\n*opens link*...            anime\n",
      "12  12  omg i was thinking the same.... azumi u the al...            anime\n",
      "13  13  One shot, one kill!\\nWait... that's not the ri...        Overwatch\n",
      "14  14  I'm new to this sub and I was curious. Is the ...            trees\n",
      "15  15  I pay $220/oz in Brooklyn for mid range trees....            trees\n",
      "16  16  I'm glad you're considering a rewatch. This se...            anime\n",
      "17  17  And it's been the same stories all window, sam...           soccer\n",
      "18  18  Not willing to negotiate a contract well after...           soccer\n",
      "19  19  Afraid I'll get addicted and fail school or sm...  GlobalOffensive\n",
      "2968210\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# based on tutorial from https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "df = pd.read_csv('reddit-comment-classification-comp-551/reddit_train.csv')\n",
    "df = df[pd.notnull(df['comments'])]\n",
    "print(df.head(20))\n",
    "print(df['comments'].apply(lambda x: len(x.split(' '))).sum())\n",
    "\n",
    "\n",
    "\n",
    "df.subreddits.value_counts().plot(kind='bar');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are balanced, but the text needs cleaning. Here's some cleaning (we should customize **TODO: we should make something to remove links... that is words starting with `http://` at least, should be ignored**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "ignored_symbols = re.compile('[^0-9a-z #+_]')\n",
    "#nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def print_plot(index):\n",
    "    example = df[df.index == index][['comments', 'subreddits']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('subreddit:', example[1])\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string (one comment)\n",
    "        return: modified string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = delimiters.sub(' ', text) # replace delimiters symbols by space in text\n",
    "    text = ignored_symbols.sub('', text) # delete symbols which are in ignored_symbols from text\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords) # delete stopwords from text\n",
    "    return text\n",
    "    \n",
    "df['comments'] = df['comments'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to lemmatize the corpus.  This might not help in the short term, but will be useful to play with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                           comments       subreddits\n",
      "0   0  honest buffalo correct answ rememb peopl somew...           hockey\n",
      "1   1  ah ye way could rememb draft thought gon na gr...              nba\n",
      "2   2  https youtub 6xxbbr8isz0t40m49sif didnt find a...  leagueoflegends\n",
      "3   3  wouldnt bad sign wouldnt paid 18m euro right p...           soccer\n",
      "4   4  easy us piss dry techn let drop let dry rins r...            funny\n",
      "5   5                                  jok you seen twic            funny\n",
      "6   6  rol mi3 on best vil iv seen movy genuin felt l...           movies\n",
      "7   7  akag stil alph fuck sugawar suff definit two f...            anime\n",
      "8   8  think oth deton wouldnt prov jok right blew bo...           movies\n",
      "9   9  right disrupt tank pul dps frey pick get point...        Overwatch\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "def lemmatize_sentence(sen):\n",
    "    \"\"\" lemmatizes every word in space separated sentence sen\"\"\" \n",
    "    token_list = word_tokenize(sen)\n",
    "    lemma_sen = []\n",
    "    for w in token_list:\n",
    "        lemma_sen.append(stemmer.stem(w))\n",
    "    return \" \".join(lemma_sen)\n",
    "\n",
    "df['comments'] = df['comments'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "# print_plot(1234)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could set the train test split here, or we could do some more processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_array = np.unique(df.subreddits.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get **a list of words in the entire corpus of comments** (that is, `tokens`), and also **a list unique words** (that is `types`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens 1601210\n",
      "number of types 75440\n"
     ]
    }
   ],
   "source": [
    "# import itertools\n",
    "\n",
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words are more common than others.  We might want to do something with this. But for now it's just useful to have the information.  I'll make an uncommon-word list. We can remove them just like we did the stopwords. We'll do this later, with scikitlearn's CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6ceade4757d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcommon_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype_counts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "# common_words = types[type_counts > 20]\n",
    "# len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsize_vocab(text):\n",
    "#     text = ' '.join(word for word in text.split() if word in common_words) # keep only common words\n",
    "#     return text\n",
    "    \n",
    "# df['comments'] = df['comments'].apply(downsize_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_list = df['comments'].apply(lambda x: word_tokenize(x)).values\n",
    "\n",
    "# tokens = np.array(list(itertools.chain.from_iterable(tokens_list)))\n",
    "\n",
    "# types, type_counts = np.unique(tokens, return_counts=True)\n",
    "\n",
    "# print(\"number of tokens\",len(tokens))\n",
    "# print(\"number of types\",len(types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.comments, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tfidf = TfidfTransformer()\n",
    "#X_tfidf = tfidf.fit_transform(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df.subreddits, test_size=0.3, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running sklearn classifier model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ct_vect__max_features': 10000, 'ct_vect__ngram_range': (1, 1)}\n",
      "accuracy 0.44961904761904764\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.21      0.17      0.19      1039\n",
      "GlobalOffensive       0.46      0.55      0.50      1028\n",
      "          Music       0.57      0.60      0.58      1011\n",
      "      Overwatch       0.48      0.67      0.56      1085\n",
      "          anime       0.33      0.59      0.42      1067\n",
      "       baseball       0.64      0.43      0.51      1091\n",
      "         canada       0.49      0.35      0.41      1012\n",
      "     conspiracy       0.43      0.28      0.34      1019\n",
      "         europe       0.47      0.44      0.46      1084\n",
      "          funny       0.19      0.17      0.18      1053\n",
      "  gameofthrones       0.73      0.64      0.68      1050\n",
      "         hockey       0.22      0.69      0.33      1013\n",
      "leagueoflegends       0.69      0.47      0.56      1013\n",
      "         movies       0.48      0.49      0.49      1054\n",
      "            nba       0.62      0.47      0.53      1074\n",
      "            nfl       0.71      0.39      0.50      1042\n",
      "         soccer       0.62      0.44      0.51      1125\n",
      "          trees       0.44      0.46      0.45      1072\n",
      "      worldnews       0.39      0.19      0.26      1048\n",
      "            wow       0.70      0.53      0.60      1020\n",
      "\n",
      "       accuracy                           0.45     21000\n",
      "      macro avg       0.49      0.45      0.45     21000\n",
      "   weighted avg       0.50      0.45      0.45     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bernoulli_nb = Pipeline([\n",
    "                         ('ct_vect', CountVectorizer()),\n",
    "#                          ('tfidf', TfidfTransformer()),\n",
    "                         ('clf', BernoulliNB()),\n",
    "                        ])\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                       alpha=1e-3, random_state=27,\n",
    "                                       max_iter=5, tol=None)),\n",
    "                ])\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = Pipeline([\n",
    "                 ('ct_vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', KNeighborsClassifier(n_neighbors=100)),\n",
    "                ])\n",
    "\n",
    "\n",
    "def paramsearch(modelpipeline):\n",
    "    '''\n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    does gridsearch on the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    parameters = {\n",
    "        'ct_vect__ngram_range': [(1,1)],\n",
    "        'ct_vect__max_features': [10000],\n",
    "#         'tfidf__use_idf': (False),\n",
    "#         'clf__alpha': (1e-4, 1e-5),\n",
    "    }\n",
    "\n",
    "    gridsearch = GridSearchCV(modelpipeline, parameters, cv=5, iid=False, n_jobs=-1)\n",
    "    gridsearch = gridsearch.fit(X_train, y_train)\n",
    "    y_pred = gridsearch.predict(X_test)\n",
    "#     print(gridsearch)\n",
    "    print(gridsearch.best_params_)\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred, target_names=values_array))\n",
    "\n",
    "def runmodel(modelpipeline):\n",
    "    ''' \n",
    "    modelpipeline: sklearn.pipeline.Pipeline object \n",
    "    runs the given pipeline on test split and prints classification report\n",
    "    '''\n",
    "    modelpipeline.fit(X_train, y_train)\n",
    "    y_pred = modelpipeline.predict(X_test)\n",
    "    print(modelpipeline)\n",
    "    print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    print(classification_report(y_test, y_pred,target_names=values_array))\n",
    "\n",
    "paramsearch(knn)\n",
    "\n",
    "#runmodel(sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_naive_bayes(observations, y, num_features,smoothing):\n",
    "\n",
    "    #Initialize marginal probability for each class\n",
    "    count_class = np.array(20*[[0]])\n",
    "    marg_prob = np.array(20*[[1]]) #Laplace smoothing, starting counts with 1\n",
    "\n",
    "    #Initialize matrix of probabilities of observed features given k\n",
    "    cond_prob_matrix = np.ones((20,num_features)) * smoothing\n",
    "\n",
    "    \n",
    "    #compute marginal probability of each class\n",
    "    total_comments = y.shape[0]\n",
    "    for j in range(total_comments):\n",
    "        count_class[y[j]] += 1\n",
    "    \n",
    "    #Marginal probability for each class\n",
    "    marg_prob = np.true_divide(count_class, total_comments)\n",
    "\n",
    "    \n",
    "    observ = observations.nonzero()\n",
    "    for i in range(observations.shape[0]):\n",
    "        feature_no = observ[1][i]\n",
    "        comment_no = observ[0][i]\n",
    "       \n",
    "        comment_class = y[comment_no]\n",
    "        cond_prob_matrix[comment_class][feature_no] += 1\n",
    "\n",
    "    #divide each row of cond_prob_matrix by the count of comments per class\n",
    "    for i in range(20):\n",
    "        cond_prob_matrix[i] = np.true_divide(cond_prob_matrix[i], count_class[i])\n",
    "\n",
    "\n",
    "    cond_prob_matrix = cond_prob_matrix.transpose()\n",
    "    marg_prob = np.log(marg_prob)\n",
    "\n",
    "    return marg_prob, cond_prob_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "        \"anime\": 1,\n",
    "        \"AskReddit\": 2,\n",
    "        \"baseball\": 3,\n",
    "        \"canada\": 4, \n",
    "        \"conspiracy\": 5, \n",
    "        \"europe\": 6, \n",
    "        \"funny\": 7, \n",
    "        \"gameofthrones\": 8, \n",
    "        \"GlobalOffensive\": 9,\n",
    "        \"hockey\" :10, \n",
    "        \"leagueoflegends\": 11, \n",
    "        \"movies\": 12, \n",
    "        \"Music\": 13, \n",
    "        \"nba\":14, \n",
    "        \"nfl\":15, \n",
    "        \"Overwatch\":16, \n",
    "        \"soccer\":17, \n",
    "        \"trees\":18, \n",
    "        \"worldnews\":19, \n",
    "        \"wow\":0\n",
    "    }\n",
    "\n",
    "y_traindf = pd.DataFrame(y_train)\n",
    "y_traindf['subreddits']= y_traindf['subreddits'].map(classes)\n",
    "y_train_array = np.array(y_traindf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=5000)\n",
    "X_train_tf = cv.fit_transform(X_train)\n",
    "X_test_tf = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from naive_bayes import fit_naive_bayes\n",
    "prior, conditional = fit_naive_bayes(X_train_tf, y_train_array, X_train_tf.shape[1],0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.03225806e-05, 4.11015208e-05, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.53047776e-04, 4.48613377e-04],\n",
       "       [4.43548387e-04, 4.11015208e-05, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.11861614e-05, 4.48613377e-04],\n",
       "       [4.43548387e-04, 4.11015208e-05, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.11861614e-05, 4.07830343e-05],\n",
       "       ...,\n",
       "       [4.03225806e-05, 4.52116728e-04, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.11861614e-05, 4.07830343e-05],\n",
       "       [1.25000000e-03, 4.11015208e-05, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.11861614e-05, 4.07830343e-05],\n",
       "       [4.03225806e-05, 4.11015208e-05, 4.06338887e-05, ...,\n",
       "        4.21052632e-05, 4.11861614e-05, 4.07830343e-05]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list = X_test.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "def predict_naive_bayes(id_list, observations, marg_prob, cond_prob_matrix):\n",
    "\n",
    "    #log of inverse conditional probability matrix\n",
    "    inv_cond_prob_matrix = np.ones((cond_prob_matrix.shape[0], cond_prob_matrix.shape[1]))\n",
    "    inv_cond_prob_matrix = inv_cond_prob_matrix - cond_prob_matrix\n",
    "    inv_cond_prob_matrix = sparse.csr_matrix(np.log(inv_cond_prob_matrix))\n",
    "\n",
    "    #log of conditional probability matrix\n",
    "    cond_prob_matrix = sparse.csr_matrix(np.log(cond_prob_matrix))\n",
    "    \n",
    "    # 0s become 1s, 1s become 0s\n",
    "    sparse_ones = sparse.csr_matrix(np.ones((observations.shape[0], observations.shape[1])))\n",
    "    complement_obs = sparse_ones - observations\n",
    "\n",
    "    prob_per_class = np.dot(observations,cond_prob_matrix) + np.dot(complement_obs,inv_cond_prob_matrix)\n",
    "    #print(prob_per_class)\n",
    "    y = []\n",
    "    for i in range(observations.shape[0]):\n",
    "        prob_per_class[i] += marg_prob.transpose()\n",
    "        y.append(np.argmax(prob_per_class[i]))\n",
    "        \n",
    "    id_list = np.array(id_list).transpose()\n",
    "\n",
    "    matrix = np.stack((id_list, y)).transpose()\n",
    "    df_pred = pd.DataFrame(matrix)\n",
    "\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_naive_bayes(ID_list, X_test_tf, prior, conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26505</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16099</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35596</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62735</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>67323</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20995</td>\n",
       "      <td>23873</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20996</td>\n",
       "      <td>15156</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20997</td>\n",
       "      <td>1645</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20998</td>\n",
       "      <td>4919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20999</td>\n",
       "      <td>50805</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1\n",
       "0      26505   2\n",
       "1      16099  19\n",
       "2      35596  19\n",
       "3      62735   8\n",
       "4      67323   6\n",
       "...      ...  ..\n",
       "20995  23873   9\n",
       "20996  15156  18\n",
       "20997   1645  15\n",
       "20998   4919   4\n",
       "20999  50805   4\n",
       "\n",
       "[21000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testdf = pd.DataFrame(y_test)\n",
    "y_testdf['subreddits']= y_testdf['subreddits'].map(classes)\n",
    "y_test_array = np.array(y_testdf['subreddits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1        19\n",
       "2        19\n",
       "3         8\n",
       "4         6\n",
       "         ..\n",
       "20995     9\n",
       "20996    18\n",
       "20997    15\n",
       "20998     4\n",
       "20999     4\n",
       "Name: 1, Length: 21000, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df_pred, df_true_y):\n",
    "\n",
    "    pred = np.array(df_pred[1])\n",
    "    true_y = np.array(df_true_y['subreddits'])\n",
    "\n",
    "    count = 0\n",
    "    total = len(true_y)\n",
    "    for i in range(total):\n",
    "        if pred[i] == true_y[i]:\n",
    "            count +=1\n",
    "            \n",
    "    return float(count)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3038095238095238\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      AskReddit       0.41      0.44      0.43      1020\n",
      "GlobalOffensive       0.30      0.43      0.36      1067\n",
      "          Music       0.13      0.13      0.13      1039\n",
      "      Overwatch       0.50      0.15      0.23      1091\n",
      "          anime       0.16      0.57      0.25      1012\n",
      "       baseball       0.22      0.24      0.23      1019\n",
      "         canada       0.28      0.32      0.30      1084\n",
      "     conspiracy       0.18      0.06      0.09      1053\n",
      "         europe       0.43      0.55      0.48      1050\n",
      "          funny       0.40      0.31      0.35      1028\n",
      "  gameofthrones       0.36      0.25      0.30      1013\n",
      "         hockey       0.37      0.33      0.35      1013\n",
      "leagueoflegends       0.31      0.25      0.28      1054\n",
      "         movies       0.32      0.54      0.40      1011\n",
      "            nba       0.49      0.23      0.31      1074\n",
      "            nfl       0.50      0.18      0.27      1042\n",
      "         soccer       0.45      0.45      0.45      1085\n",
      "          trees       0.42      0.21      0.28      1125\n",
      "      worldnews       0.34      0.29      0.31      1072\n",
      "            wow       0.18      0.16      0.17      1048\n",
      "\n",
      "       accuracy                           0.30     21000\n",
      "      macro avg       0.34      0.31      0.30     21000\n",
      "   weighted avg       0.34      0.30      0.30     21000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predictions, y_testdf))\n",
    "print(classification_report(y_testdf['subreddits'], predictions[1], target_names = values_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
